{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План:\n",
    "1. Python\n",
    "2. Numpy\n",
    "3. Pandas\n",
    "4. Regexp + regexp with dataframes\n",
    "5. <b>Texts</b>\n",
    "6. Matplotlib, Seaborn\n",
    "7. Classification, clustering, binary, multiclass, multilabel\n",
    "8. Metrics\n",
    "9. Feature extraction\n",
    "10. Pyspark/sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXTS\n",
    "\n",
    "Рассмотрим:\n",
    "\n",
    "* предобработку текста\n",
    "* представление текста\n",
    "* понятие эмбеддинга\n",
    "* текстовую классификацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"400px\" src=\"https://media.giphy.com/media/nopqz91prOyvS/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Предобработка текста\n",
    "\n",
    "Текст на естественном языке, который нужно обрабатывать в задачах машинного обучения, сильно зависит от источника. Пример:\n",
    "\n",
    "Википедия\n",
    "> Литературный язык — обработанная часть общенародного языка, обладающая в большей или меньшей степени письменно закреплёнными нормами; язык всех проявлений культуры, выражающихся в словесной форме.\n",
    "\n",
    "Твиттер\n",
    "> Если у вас в компании есть люди, которые целый день сидят в чатиках и смотрят видосики, то, скорее всего, это ДАТАСАЕНТИСТЫ и у них ОБУЧАЕТСЯ\n",
    "\n",
    "Ответы@Mail.ru\n",
    "> как пишется \"Вообщем лето было отличное\" раздельно или слитно слово ВОобщем?? ?\n",
    "\n",
    "В связи с этим, возникает задача предобработки (или нормализации) текста, то есть приведения к некоторому единому виду."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Приведение текста к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'купил таблетки от тупости, но не смог открыть банку,ЧТО ДЕЛАТЬ???'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'купил таблетки от тупости, но не смог открыть банку,что делать???'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Удаление неинформативных символов.\n",
    "\n",
    "Такими символами могут быть символы пунктуации, спец-символы, повторяющиеся символы, цифры.\n",
    "Удалите символы пунктуации и лишние пробелы из предыдущего текста в нижнем регистре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(\\?|,)'\n",
    "text = ' '.join(re.sub(pattern, ' ', text).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Разбиение текста на смысловые единицы (токенизация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Купите кружку-термос \"Hello Kitty\" на 0.5л (64см³) за 300 рублей. До 01.01.2020.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой подход к токенизации - это разбиение по текста по пробельным символам. \n",
    "\n",
    "**Quiz: Какая у этого подхода есть проблема?**\n",
    "\n",
    "- Объем словаря будет большим. В текстах могут встретится как слова **кружка**, **термос** по отдельности так и через тире **кружка-термос** - и при использовании простых способов векторизации текстов это будут 3 разных смысловых единицы, хотя логично было бы оставить 2.\n",
    "\n",
    "- Если перед нами стоит задача, в которой необходимо учитывать пунктуацию, то нам придется придумывать способ оторвать точки, кавычки, скобки от слов\n",
    "    \n",
    "- Если пробелы пропущены, то два слова могут остаться склееными через запятую\\точку\\дефис"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другие способы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке для морфологического анализа для русского языка [`pymorphy2`](https://pymorphy2.readthedocs.io/en/latest/) есть простая вспомогательная функция для токенизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "\n",
    "##your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Купите',\n",
       " 'кружку-термос',\n",
       " '\"',\n",
       " 'Hello',\n",
       " 'Kitty',\n",
       " '\"',\n",
       " 'на',\n",
       " '0',\n",
       " '.',\n",
       " '5л',\n",
       " '(',\n",
       " '64см³',\n",
       " ')',\n",
       " 'за',\n",
       " '300',\n",
       " 'рублей',\n",
       " '.',\n",
       " 'До',\n",
       " '01',\n",
       " '.',\n",
       " '01',\n",
       " '.',\n",
       " '2020',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более сложной метод токенизации представлен в [`nltk`](https://www.nltk.org/): библиотеке для общего NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравните и напишите в комментарии чем отличаются эти три метода**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Купите кружку-термос \"Hello Kitty\" на 0.5л (64см³) за 300 рублей.',\n",
       " 'До 01.01.2020.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Купите',\n",
       " 'кружку-термос',\n",
       " '``',\n",
       " 'Hello',\n",
       " 'Kitty',\n",
       " \"''\",\n",
       " 'на',\n",
       " '0.5л',\n",
       " '(',\n",
       " '64см³',\n",
       " ')',\n",
       " 'за',\n",
       " '300',\n",
       " 'рублей',\n",
       " '.',\n",
       " 'До',\n",
       " '01.01.2020',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Купите',\n",
       " 'кружку',\n",
       " '-',\n",
       " 'термос',\n",
       " '\"',\n",
       " 'Hello',\n",
       " 'Kitty',\n",
       " '\"',\n",
       " 'на',\n",
       " '0',\n",
       " '.',\n",
       " '5л',\n",
       " '(',\n",
       " '64см³',\n",
       " ')',\n",
       " 'за',\n",
       " '300',\n",
       " 'рублей',\n",
       " '.',\n",
       " 'До',\n",
       " '01',\n",
       " '.',\n",
       " '01',\n",
       " '.',\n",
       " '2020',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize\n",
    "# возращает токены по предложениям, разделенные по точке\n",
    "\n",
    "# word_tokenize\n",
    "# возвращает токены в виде слов разделленных по пробелу\n",
    "\n",
    "# wordpunct_tokenize\n",
    "# возвращает токены в виде слов разделенных по пробелу точке пунктиру (специальному символу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для русского языка также есть новая специализированная библиотека [`razdel`](https://github.com/natasha/razdel).\n",
    "\n",
    "**Напишите функцию, которая принимает на вход текст и возвращает список токенов из метода tokenize библиотеки razdel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['югославской',\n",
       " 'историографии',\n",
       " 'также',\n",
       " 'известна',\n",
       " 'как',\n",
       " '«',\n",
       " 'Седьмое',\n",
       " 'вражеское',\n",
       " 'наступление',\n",
       " '»',\n",
       " 'или',\n",
       " 'Десант',\n",
       " 'на',\n",
       " 'Дрвар',\n",
       " '(',\n",
       " 'сербохорв',\n",
       " '.',\n",
       " 'Десант',\n",
       " 'на',\n",
       " 'Дрвар',\n",
       " '/',\n",
       " 'Desant',\n",
       " 'na',\n",
       " 'Drvar',\n",
       " ')',\n",
       " '—',\n",
       " 'комбинированная',\n",
       " 'воздушно-десантная',\n",
       " 'и',\n",
       " 'сухопутная',\n",
       " 'наступательная',\n",
       " 'операция',\n",
       " 'войск',\n",
       " '2-й',\n",
       " 'танковой',\n",
       " 'армии',\n",
       " 'вермахта',\n",
       " 'во',\n",
       " 'время',\n",
       " 'Второй',\n",
       " 'мировой',\n",
       " 'войны',\n",
       " '.',\n",
       " 'Проводилась',\n",
       " 'в',\n",
       " 'Западной',\n",
       " 'Боснии',\n",
       " 'в',\n",
       " 'районе',\n",
       " 'Бугойно',\n",
       " '—',\n",
       " 'Яйце',\n",
       " '—',\n",
       " 'Баня-Лука',\n",
       " '—',\n",
       " 'Приедор',\n",
       " '—',\n",
       " 'Бихач',\n",
       " '—',\n",
       " 'Книн',\n",
       " 'в',\n",
       " 'период',\n",
       " 'с',\n",
       " '25',\n",
       " 'мая',\n",
       " 'по',\n",
       " '6',\n",
       " 'июня',\n",
       " '1944',\n",
       " 'года',\n",
       " 'с',\n",
       " 'целью',\n",
       " 'уничтожения',\n",
       " 'Верховного',\n",
       " 'штаба',\n",
       " 'НОАЮ',\n",
       " 'в',\n",
       " 'городе',\n",
       " 'Дрвар',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'находившихся',\n",
       " 'при',\n",
       " 'нём',\n",
       " 'учреждений',\n",
       " 'народно-освободительного',\n",
       " 'движения',\n",
       " 'Югославии',\n",
       " 'и',\n",
       " 'союзных',\n",
       " 'военных',\n",
       " 'миссий',\n",
       " '.',\n",
       " 'В',\n",
       " 'операции',\n",
       " 'участвовали',\n",
       " '500-й',\n",
       " 'парашютно-десантный',\n",
       " 'батальон',\n",
       " 'СС',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'части',\n",
       " '15-го',\n",
       " 'горнопехотного',\n",
       " 'армейского',\n",
       " 'корпуса',\n",
       " 'и',\n",
       " '5-го',\n",
       " 'горнопехотного',\n",
       " 'корпуса',\n",
       " 'СС',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "\n",
    "def tokenize_with_razdel(text):\n",
    "    tokens = list(tokenize(text))\n",
    "    tokens = [_.text for _ in tokens]\n",
    "    return tokens\n",
    "tokenize_with_razdel(text)\n",
    "\n",
    "## Но я не понял как это работает!\n",
    "\n",
    "##your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Приведение слов к нормальной форме (стемминг, лемматизация)\n",
    "\n",
    "**Стемминг - это нормализация слова путём отбрасывания окончания по правилам языка.**\n",
    "\n",
    "Такая нормализация хорошо подходит для языков с небольшим разнообразием словоформ, например, для английского. В библиотеке nltk есть несколько реализаций стеммеров:\n",
    " - Porter stemmer\n",
    " - Snowball stemmer - только его можно использовать для русского языка (но лучше не надо)\n",
    " - Lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "SnowballStemmer(language='english').stem('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для русского языка этот подход не очень подходит, поскольку в русском есть падежные формы, время у глаголов и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бежа'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer(language='russian').stem('бежать')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лемматизация - приведение слов к начальной морфологической форме (с помощью словаря и грамматики языка).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две самые часто используемые библиотеки для лемматизации русских слов:\n",
    "- [pymorphy2](https://pymorphy2.readthedocs.io/en/latest/)\n",
    "- [mystem3](https://tech.yandex.ru/mystem/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой подход к лемматизации - словарный. Здесь не учитывается контекст слова, поэтому для омонимов такой подход работает не всегда. Такой подход применяет библиотека pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "pymorphy = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишите функцию принимающую на вход список токенов и возвращаюшую список лемматизированных с помощью pymorphy токенов**\n",
    "\n",
    "протестируйте на примере 'на заводе стали увидел виды стали'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_pymorphy(tokens):\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = pymorphy.parse(tokens[i])[0].normal_form\n",
    "    return(tokens) ##your code\n",
    "\n",
    "\n",
    "##your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['на', 'завод', 'стать', 'увидеть', 'вид', 'стать']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'на заводе стали увидел виды стали'\n",
    "lemmatize_with_pymorphy(tokenize_with_razdel(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека от Яндекса `mystem3` обходит это ограничение и рассматривает контекст слова, используя статистику и правила. + Имеет свой токенизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишите функцию принимающую на вход строку и возвращаюшую список лемматизированных токенов с помощью pymystem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'на заводе стали увидел виды стали'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem()\n",
    "\n",
    "\n",
    "# def lemmatize_with_mystem(text):\n",
    "    ##your code\n",
    "    \n",
    "##your code\n",
    "mystem.lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще более крутая и более **медленная** библиотека `RNNMorph` базирующаяся на рекурентных сетях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'на заводе стали увидел виды стали'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "\n",
    "# def lemmatize_with_rnnmorph(tokens):\n",
    "    #you know what to do\n",
    "pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 One-Hot Encoding\n",
    "<img src=\"gifs/one_hot.png\" width=\"500\">\n",
    "\n",
    "При таком способе представления текстов, составляется словарь всех слов со всех документов - столбцы нашей матрицы, строки это документы. \n",
    "\n",
    "Если слово есть в документе на пересечении столбца и строки ставится 1, иначе 0. \n",
    "\n",
    "Матрица сформированная таким образом получается разреженной, т.е. если у нас очень много уникальных слов, доля единиц в строке будет маленькой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы уже получали one-hot вектора с помощью pandas\\numpy. \n",
    "Сначала нам нужно каждому слову поставить в соответствие номер, а затем перевести их в бинарные вектора. \n",
    "\n",
    "В этот раз используем библиотеку scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "words = ['What', 'the', 'hell', 'What']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получите one-hot вектора используя LabelEncoder и OneHotEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(words)\n",
    "le.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "value = ohe.fit_transform(np.array(words).reshape(-1,1))\n",
    "print(value)\n",
    "# ohe.transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что будет, если мы сложим все one-hot вектора слов в тексте?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2., 1., 1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bag-of-words\n",
    "\n",
    "В прошлом методе, если слово употребляется в тексте на пересечении столбца-слова и строки-документа ставились 1, но теперь мы бы хотели так же знать сколько раз слово встретилось в данном документе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы посчитать количество слов в тексте, используем метод CountVectorizer из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Кот пьет молоко',\n",
    "    'Кто пьет молоко?',\n",
    "    'Молоко выпивается котом',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите CountVectorizer на примерах, выведите вектора для трех предложений и список слов-столбцов матрицы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "##your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['выпивается', 'кот', 'котом', 'кто', 'молоко', 'пьет']\n",
      "[[0 1 0 0 1 1]\n",
      " [0 0 0 1 1 1]\n",
      " [1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)\n",
    "print(cv.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TF-IDF\n",
    "\n",
    "**Term Frequency**  $tf(w,d)$ - сколько раз слово $w$ встретилось в документе $d$\n",
    "\n",
    "**Document Frequency** $df(w)$ - сколько документов содержат слово $w$\n",
    "\n",
    "**Inverse Document Frequency** $idf(w) = log_2(N/df(w))$  — обратная документная частотность. \n",
    "\n",
    "**TF-IDF**=$tf(w,d)*idf(w)$\n",
    "\n",
    "В гите есть презентация, с которой возможно, станет понятнее **`векторайзеры и метрики.pptx`**\n",
    "\n",
    "**Обучите TfidfVectorizer на примерах из предыдущего задания, выведите вектора для трех предложений и список слов-столбцов матрицы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "##your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кот пьет молоко', 'Кто пьет молоко?', 'Молоко выпивается котом']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['выпивается', 'кот', 'котом', 'кто', 'молоко', 'пьет']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.72033345, 0.        , 0.        , 0.42544054,\n",
       "        0.54783215],\n",
       "       [0.        , 0.        , 0.        , 0.72033345, 0.42544054,\n",
       "        0.54783215],\n",
       "       [0.65249088, 0.        , 0.65249088, 0.        , 0.38537163,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы попробуем применить описание методы предобработки и представления текста на примере анализа тональности текста. В качестве данных будем использовать небольшой датасет твитов. Всего в данных 2 класса: позитив и негатив."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Загрузка данных и получение тренировочной и тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6929, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../../data/train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>эти розы для прекрасной мамочки)))=_=]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>И да, у меня в этом году серьезные проблемы со...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>♥Обожаю людей, которые заставляют меня смеятьс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Вчера нашла в почтовом ящике пустую упаковку и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>очень долгожданный и хороший день был)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  positive            эти розы для прекрасной мамочки)))=_=]]\n",
       "1  negative  И да, у меня в этом году серьезные проблемы со...\n",
       "2  positive  ♥Обожаю людей, которые заставляют меня смеятьс...\n",
       "3  negative  Вчера нашла в почтовом ящике пустую упаковку и...\n",
       "4  positive             очень долгожданный и хороший день был)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбейте выборку на две тренировочную и валидационную с помощью функции train_test_split из sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['label'], stratify=train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверьте что доли классов на train и на test совпадают**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689761354888376"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 'positive'])/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687824581650318"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test == 'positive'])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33121754183496827"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test != 'positive'])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33102386451116245"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train != 'positive'])/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша выборка не сбалансирована (доля одно из класса значительно ниже доли другого), поэтому стандартные метрики качества для классификаторов вроде accuracy или roc auc нам не подходят"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужна Точность (Precision) и Полнота (Recall)!\n",
    "\n",
    "**Про эти метрики можно подробно почитать в презентации  `векторайзеры и метрики.pptx`**\n",
    "\n",
    "Для подсчета метрик будем использовать говоторые функции из sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для оценки векторизатора. В качестве модели будем использовать линейный SVM, он хорошо работает на задачах классификации текстов, когда для векторизации используются методы дающие разреженные матрицы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуйте функцию следуя инструкциям в комментариях**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'я не понял как это задание делать, поэтому что получиться то получиться, я не виноват.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorph = MorphAnalyzer()\n",
    "corpus = simple_word_tokenize(text)\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = pymorph.parse(corpus[i])[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['А это саундтрек к одному классному фильму. :)',\n",
       "       'Это был самый лучший отряд!:) Спасибо вам, ребята!:)',\n",
       "       'Президент чувашии под неее классно двигается))))))))))', ...,\n",
       "       'Мне одному хотелось в момент объявления названия лучшего фильма выбросить ноутбук в окно?',\n",
       "       'от длительного сидения дома я начала испытывать серьёзные сложности с устным выражением своих мыслей.....',\n",
       "       'брат почитай эт писец))) я под столом'], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5196, 18149)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['label'], stratify=train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_vectorizer(vectorizer):\n",
    "    #обучение выбранного векторайзера и получение веторов текстов (fit_transform)  \n",
    "    global X_train, X_test, y_test, y_train\n",
    "    Xtr = vectorizer.fit_transform(np.array(X_train))\n",
    "    X_train = Xtr.toarray()\n",
    "    #иницилизация классификатора и тренировка модели\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #получение векторов текстов для теста\n",
    "    Xte = vectorizer.transform(np.array(X_test))\n",
    "    X_test = Xte.toarray()\n",
    "                                   \n",
    "    #получение предсказания\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #вывод метрик классификации с помощью функции classification_report - выводит precision и recall для каждого класса\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #возвращаем предсказанные классы для теста\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5196, 18177)\n",
      "(1733, 18177)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.56      0.65       574\n",
      "    positive       0.81      0.91      0.86      1159\n",
      "\n",
      "    accuracy                           0.80      1733\n",
      "   macro avg       0.79      0.74      0.75      1733\n",
      "weighted avg       0.79      0.80      0.79      1733\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', ..., 'positive', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "evaluate_vectorizer(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Сравнение способов представления текста\n",
    "\n",
    "* необработанный текст + используйте CountVectorizer\n",
    "* переведите в lower и используйте CountVectorizer\n",
    "* lower + lemmatization + CountVectorizer\n",
    "* lower + stemming (SnowballStemer) + CountVectorizer\n",
    "Выберите лучший из двух последних ->\n",
    "* lower + lemmatization\\stemming + CountVectorizer + передавайте в векторайзер свой токенизатор (например из razdel)\n",
    "* lower + lemmatization\\stemming + CountVectorizer + передавайте в векторайзер свой токенизатор (например из razdel) + передайте список стоп слов (data/stopwords-ru.txt)\n",
    "* lower + lemmatization\\stemming + TfidfVectorizer + передавайте в векторайзер свой токенизатор (например из razdel)\n",
    "* lower + lemmatization\\stemming + TfidfVectorizer (используйте ngrams(2, 2)) + передавайте в векторайзер свой токенизатор (например из razdel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"югославской историографии также известна как «Седьмое вражеское наступление» или Десант на Дрвар (сербохорв. Десант на Дрвар / Desant na Drvar) — комбинированная воздушно-десантная и сухопутная наступательная операция войск 2-й танковой армии вермахта во время Второй мировой войны. Проводилась в Западной Боснии в районе Бугойно — Яйце — Баня-Лука — Приедор — Бихач — Книн в период с 25 мая по 6 июня 1944 года с целью уничтожения Верховного штаба НОАЮ в городе Дрвар, а также находившихся при нём учреждений народно-освободительного движения Югославии и союзных военных миссий. В операции участвовали 500-й парашютно-десантный батальон СС, а также части 15-го горнопехотного армейского корпуса и 5-го горнопехотного корпуса СС.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### необработанный текст + используйте CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([text])\n",
    "# cv.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2],\n",
       "       [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([text.split(), text.split()]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# переведите в lower и используйте CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейского',\n",
       " 'армии',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'боснии',\n",
       " 'бугойно',\n",
       " 'вермахта',\n",
       " 'верховного',\n",
       " 'во',\n",
       " 'военных',\n",
       " 'воздушно',\n",
       " 'войны',\n",
       " 'войск',\n",
       " 'вражеское',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'го',\n",
       " 'года',\n",
       " 'горнопехотного',\n",
       " 'городе',\n",
       " 'движения',\n",
       " 'десант',\n",
       " 'десантная',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западной',\n",
       " 'известна',\n",
       " 'или',\n",
       " 'историографии',\n",
       " 'июня',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинированная',\n",
       " 'корпуса',\n",
       " 'лука',\n",
       " 'мая',\n",
       " 'мировой',\n",
       " 'миссий',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательная',\n",
       " 'наступление',\n",
       " 'находившихся',\n",
       " 'ноаю',\n",
       " 'нём',\n",
       " 'операции',\n",
       " 'операция',\n",
       " 'освободительного',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'проводилась',\n",
       " 'районе',\n",
       " 'седьмое',\n",
       " 'сербохорв',\n",
       " 'союзных',\n",
       " 'сс',\n",
       " 'сухопутная',\n",
       " 'также',\n",
       " 'танковой',\n",
       " 'уничтожения',\n",
       " 'участвовали',\n",
       " 'учреждений',\n",
       " 'целью',\n",
       " 'части',\n",
       " 'штаба',\n",
       " 'югославии',\n",
       " 'югославской',\n",
       " 'яйце']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([text.lower()])\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + lemmatization + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = simple_word_tokenize(text.lower())\n",
    "pymorph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = pymorph.parse(corpus[i])[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = ' '.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([new_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейский',\n",
       " 'армия',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'босния',\n",
       " 'бугойный',\n",
       " 'вермахт',\n",
       " 'верховный',\n",
       " 'военный',\n",
       " 'воздушно',\n",
       " 'война',\n",
       " 'войско',\n",
       " 'вражеский',\n",
       " 'время',\n",
       " 'го',\n",
       " 'год',\n",
       " 'горнопехотный',\n",
       " 'город',\n",
       " 'два',\n",
       " 'движение',\n",
       " 'десант',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западный',\n",
       " 'известный',\n",
       " 'или',\n",
       " 'историография',\n",
       " 'июнь',\n",
       " 'как',\n",
       " 'книна',\n",
       " 'комбинированный',\n",
       " 'корпус',\n",
       " 'лука',\n",
       " 'май',\n",
       " 'мировой',\n",
       " 'миссия',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательный',\n",
       " 'наступление',\n",
       " 'находиться',\n",
       " 'ноать',\n",
       " 'он',\n",
       " 'операция',\n",
       " 'освободительный',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедора',\n",
       " 'проводиться',\n",
       " 'район',\n",
       " 'семь',\n",
       " 'сербохорв',\n",
       " 'союзный',\n",
       " 'сс',\n",
       " 'сухопутный',\n",
       " 'также',\n",
       " 'танковый',\n",
       " 'ть',\n",
       " 'уничтожение',\n",
       " 'участвовать',\n",
       " 'учреждение',\n",
       " 'цель',\n",
       " 'часть',\n",
       " 'штаб',\n",
       " 'югославия',\n",
       " 'югославский',\n",
       " 'яйцо']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 2, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейский',\n",
       " 'армия',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'босния',\n",
       " 'бугойный',\n",
       " 'вермахт',\n",
       " 'верховный',\n",
       " 'военный',\n",
       " 'воздушно',\n",
       " 'война',\n",
       " 'войско',\n",
       " 'вражеский',\n",
       " 'время',\n",
       " 'го',\n",
       " 'год',\n",
       " 'горнопехотный',\n",
       " 'город',\n",
       " 'два',\n",
       " 'движение',\n",
       " 'десант',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западный',\n",
       " 'известный',\n",
       " 'или',\n",
       " 'историография',\n",
       " 'июнь',\n",
       " 'как',\n",
       " 'книна',\n",
       " 'комбинированный',\n",
       " 'корпус',\n",
       " 'лука',\n",
       " 'май',\n",
       " 'мировой',\n",
       " 'миссия',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательный',\n",
       " 'наступление',\n",
       " 'находиться',\n",
       " 'ноать',\n",
       " 'он',\n",
       " 'операция',\n",
       " 'освободительный',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедора',\n",
       " 'проводиться',\n",
       " 'район',\n",
       " 'семь',\n",
       " 'сербохорв',\n",
       " 'союзный',\n",
       " 'сс',\n",
       " 'сухопутный',\n",
       " 'также',\n",
       " 'танковый',\n",
       " 'ть',\n",
       " 'уничтожение',\n",
       " 'участвовать',\n",
       " 'учреждение',\n",
       " 'цель',\n",
       " 'часть',\n",
       " 'штаб',\n",
       " 'югославия',\n",
       " 'югославский',\n",
       " 'яйцо']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + stemming (SnowballStemer) + CountVectorizer Выберите лучший из двух последних ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бежа'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer(language='russian').stem('бежать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'пит'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer(language='russian').stem('пить')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = simple_word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = SnowballStemmer(language='russian').stem(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['югославск',\n",
       " 'историограф',\n",
       " 'такж',\n",
       " 'известн',\n",
       " 'как',\n",
       " '«',\n",
       " 'седьм',\n",
       " 'вражеск',\n",
       " 'наступлен',\n",
       " '»',\n",
       " 'ил',\n",
       " 'десант',\n",
       " 'на',\n",
       " 'дрвар',\n",
       " '(',\n",
       " 'сербохорв',\n",
       " '.',\n",
       " 'десант',\n",
       " 'на',\n",
       " 'дрвар',\n",
       " '/',\n",
       " 'desant',\n",
       " 'na',\n",
       " 'drvar',\n",
       " ')',\n",
       " '—',\n",
       " 'комбинирова',\n",
       " 'воздушно-десантн',\n",
       " 'и',\n",
       " 'сухопутн',\n",
       " 'наступательн',\n",
       " 'операц',\n",
       " 'войск',\n",
       " '2-й',\n",
       " 'танков',\n",
       " 'арм',\n",
       " 'вермахт',\n",
       " 'во',\n",
       " 'врем',\n",
       " 'втор',\n",
       " 'миров',\n",
       " 'войн',\n",
       " '.',\n",
       " 'провод',\n",
       " 'в',\n",
       " 'западн',\n",
       " 'босн',\n",
       " 'в',\n",
       " 'район',\n",
       " 'бугойн',\n",
       " '—',\n",
       " 'яйц',\n",
       " '—',\n",
       " 'баня-лук',\n",
       " '—',\n",
       " 'приедор',\n",
       " '—',\n",
       " 'бихач',\n",
       " '—',\n",
       " 'книн',\n",
       " 'в',\n",
       " 'период',\n",
       " 'с',\n",
       " '25',\n",
       " 'ма',\n",
       " 'по',\n",
       " '6',\n",
       " 'июн',\n",
       " '1944',\n",
       " 'год',\n",
       " 'с',\n",
       " 'цел',\n",
       " 'уничтожен',\n",
       " 'верховн',\n",
       " 'штаб',\n",
       " 'ноа',\n",
       " 'в',\n",
       " 'город',\n",
       " 'дрвар',\n",
       " ',',\n",
       " 'а',\n",
       " 'такж',\n",
       " 'наход',\n",
       " 'при',\n",
       " 'нем',\n",
       " 'учрежден',\n",
       " 'народно-освободительн',\n",
       " 'движен',\n",
       " 'югослав',\n",
       " 'и',\n",
       " 'союзн',\n",
       " 'воен',\n",
       " 'мисс',\n",
       " '.',\n",
       " 'в',\n",
       " 'операц',\n",
       " 'участвова',\n",
       " '500-й',\n",
       " 'парашютно-десантн',\n",
       " 'батальон',\n",
       " 'сс',\n",
       " ',',\n",
       " 'а',\n",
       " 'такж',\n",
       " 'част',\n",
       " '15-го',\n",
       " 'горнопехотн',\n",
       " 'армейск',\n",
       " 'корпус',\n",
       " 'и',\n",
       " '5-го',\n",
       " 'горнопехотн',\n",
       " 'корпус',\n",
       " 'сс',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'арм',\n",
       " 'армейск',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'босн',\n",
       " 'бугойн',\n",
       " 'вермахт',\n",
       " 'верховн',\n",
       " 'во',\n",
       " 'воен',\n",
       " 'воздушно',\n",
       " 'войн',\n",
       " 'войск',\n",
       " 'вражеск',\n",
       " 'врем',\n",
       " 'втор',\n",
       " 'го',\n",
       " 'год',\n",
       " 'горнопехотн',\n",
       " 'город',\n",
       " 'движен',\n",
       " 'десант',\n",
       " 'десантн',\n",
       " 'дрвар',\n",
       " 'западн',\n",
       " 'известн',\n",
       " 'ил',\n",
       " 'историограф',\n",
       " 'июн',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинирова',\n",
       " 'корпус',\n",
       " 'лук',\n",
       " 'ма',\n",
       " 'миров',\n",
       " 'мисс',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательн',\n",
       " 'наступлен',\n",
       " 'наход',\n",
       " 'нем',\n",
       " 'ноа',\n",
       " 'операц',\n",
       " 'освободительн',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'провод',\n",
       " 'район',\n",
       " 'седьм',\n",
       " 'сербохорв',\n",
       " 'союзн',\n",
       " 'сс',\n",
       " 'сухопутн',\n",
       " 'такж',\n",
       " 'танков',\n",
       " 'уничтожен',\n",
       " 'участвова',\n",
       " 'учрежден',\n",
       " 'цел',\n",
       " 'част',\n",
       " 'штаб',\n",
       " 'югослав',\n",
       " 'югославск',\n",
       " 'яйц']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мне кажется что дучше работает леммитизация чем стемминг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + lemmatization\\stemming + CountVectorizer + передавайте в векторайзер свой токенизатор (например из razdel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = simple_word_tokenize(text.lower())\n",
    "\n",
    "# pymorph = MorphAnalyzer()\n",
    "\n",
    "# for i in range(len(corpus)):\n",
    "#     corpus[i] = pymorph.parse(corpus[i])[0].normal_form\n",
    "\n",
    "# cv = CountVectorizer()\n",
    "# X = cv.fit_transform(corpus)\n",
    "# cv.get_feature_names()\n",
    "\n",
    "# X.toarray().sha\n",
    "\n",
    "# new_text = ' '.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['югославской',\n",
       " 'историографии',\n",
       " 'также',\n",
       " 'известна',\n",
       " 'как',\n",
       " '«',\n",
       " 'Седьмое',\n",
       " 'вражеское',\n",
       " 'наступление',\n",
       " '»',\n",
       " 'или',\n",
       " 'Десант',\n",
       " 'на',\n",
       " 'Дрвар',\n",
       " '(',\n",
       " 'сербохорв',\n",
       " '.',\n",
       " 'Десант',\n",
       " 'на',\n",
       " 'Дрвар',\n",
       " '/',\n",
       " 'Desant',\n",
       " 'na',\n",
       " 'Drvar',\n",
       " ')',\n",
       " '—',\n",
       " 'комбинированная',\n",
       " 'воздушно-десантная',\n",
       " 'и',\n",
       " 'сухопутная',\n",
       " 'наступательная',\n",
       " 'операция',\n",
       " 'войск',\n",
       " '2-й',\n",
       " 'танковой',\n",
       " 'армии',\n",
       " 'вермахта',\n",
       " 'во',\n",
       " 'время',\n",
       " 'Второй',\n",
       " 'мировой',\n",
       " 'войны',\n",
       " '.',\n",
       " 'Проводилась',\n",
       " 'в',\n",
       " 'Западной',\n",
       " 'Боснии',\n",
       " 'в',\n",
       " 'районе',\n",
       " 'Бугойно',\n",
       " '—',\n",
       " 'Яйце',\n",
       " '—',\n",
       " 'Баня-Лука',\n",
       " '—',\n",
       " 'Приедор',\n",
       " '—',\n",
       " 'Бихач',\n",
       " '—',\n",
       " 'Книн',\n",
       " 'в',\n",
       " 'период',\n",
       " 'с',\n",
       " '25',\n",
       " 'мая',\n",
       " 'по',\n",
       " '6',\n",
       " 'июня',\n",
       " '1944',\n",
       " 'года',\n",
       " 'с',\n",
       " 'целью',\n",
       " 'уничтожения',\n",
       " 'Верховного',\n",
       " 'штаба',\n",
       " 'НОАЮ',\n",
       " 'в',\n",
       " 'городе',\n",
       " 'Дрвар',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'находившихся',\n",
       " 'при',\n",
       " 'нём',\n",
       " 'учреждений',\n",
       " 'народно-освободительного',\n",
       " 'движения',\n",
       " 'Югославии',\n",
       " 'и',\n",
       " 'союзных',\n",
       " 'военных',\n",
       " 'миссий',\n",
       " '.',\n",
       " 'В',\n",
       " 'операции',\n",
       " 'участвовали',\n",
       " '500-й',\n",
       " 'парашютно-десантный',\n",
       " 'батальон',\n",
       " 'СС',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'части',\n",
       " '15-го',\n",
       " 'горнопехотного',\n",
       " 'армейского',\n",
       " 'корпуса',\n",
       " 'и',\n",
       " '5-го',\n",
       " 'горнопехотного',\n",
       " 'корпуса',\n",
       " 'СС',\n",
       " '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = tokenize_with_razdel(text)\n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейского',\n",
       " 'армии',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'боснии',\n",
       " 'бугойно',\n",
       " 'вермахта',\n",
       " 'верховного',\n",
       " 'во',\n",
       " 'военных',\n",
       " 'воздушно',\n",
       " 'войны',\n",
       " 'войск',\n",
       " 'вражеское',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'го',\n",
       " 'года',\n",
       " 'горнопехотного',\n",
       " 'городе',\n",
       " 'движения',\n",
       " 'десант',\n",
       " 'десантная',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западной',\n",
       " 'известна',\n",
       " 'или',\n",
       " 'историографии',\n",
       " 'июня',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинированная',\n",
       " 'корпуса',\n",
       " 'лука',\n",
       " 'мая',\n",
       " 'мировой',\n",
       " 'миссий',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательная',\n",
       " 'наступление',\n",
       " 'находившихся',\n",
       " 'ноаю',\n",
       " 'нём',\n",
       " 'операции',\n",
       " 'операция',\n",
       " 'освободительного',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'проводилась',\n",
       " 'районе',\n",
       " 'седьмое',\n",
       " 'сербохорв',\n",
       " 'союзных',\n",
       " 'сс',\n",
       " 'сухопутная',\n",
       " 'также',\n",
       " 'танковой',\n",
       " 'уничтожения',\n",
       " 'участвовали',\n",
       " 'учреждений',\n",
       " 'целью',\n",
       " 'части',\n",
       " 'штаба',\n",
       " 'югославии',\n",
       " 'югославской',\n",
       " 'яйце']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(new_text)\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + lemmatization\\stemming + CountVectorizer + передавайте в векторайзер свой токенизатор (например из razdel) + передайте список стоп слов (data/stopwords-ru.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stop_word = '''c\n",
    "а\n",
    "алло\n",
    "без\n",
    "белый\n",
    "близко\n",
    "более\n",
    "больше\n",
    "большой\n",
    "будем\n",
    "будет\n",
    "будете\n",
    "будешь\n",
    "будто\n",
    "буду\n",
    "будут\n",
    "будь\n",
    "бы\n",
    "бывает\n",
    "бывь\n",
    "был\n",
    "была\n",
    "были\n",
    "было\n",
    "быть\n",
    "в\n",
    "важная\n",
    "важное\n",
    "важные\n",
    "важный\n",
    "вам\n",
    "вами\n",
    "вас\n",
    "ваш\n",
    "ваша\n",
    "ваше\n",
    "ваши\n",
    "вверх\n",
    "вдали\n",
    "вдруг\n",
    "ведь\n",
    "везде\n",
    "вернуться\n",
    "весь\n",
    "вечер\n",
    "взгляд\n",
    "взять\n",
    "вид\n",
    "видел\n",
    "видеть\n",
    "вместе\n",
    "вне\n",
    "вниз\n",
    "внизу\n",
    "во\n",
    "вода\n",
    "война\n",
    "вокруг\n",
    "вон\n",
    "вообще\n",
    "вопрос\n",
    "восемнадцатый\n",
    "восемнадцать\n",
    "восемь\n",
    "восьмой\n",
    "вот\n",
    "впрочем\n",
    "времени\n",
    "время\n",
    "все\n",
    "все еще\n",
    "всегда\n",
    "всего\n",
    "всем\n",
    "всеми\n",
    "всему\n",
    "всех\n",
    "всею\n",
    "всю\n",
    "всюду\n",
    "вся\n",
    "всё\n",
    "второй\n",
    "вы\n",
    "выйти\n",
    "г\n",
    "где\n",
    "главный\n",
    "глаз\n",
    "говорил\n",
    "говорит\n",
    "говорить\n",
    "год\n",
    "года\n",
    "году\n",
    "голова\n",
    "голос\n",
    "город\n",
    "да\n",
    "давать\n",
    "давно\n",
    "даже\n",
    "далекий\n",
    "далеко\n",
    "дальше\n",
    "даром\n",
    "дать\n",
    "два\n",
    "двадцатый\n",
    "двадцать\n",
    "две\n",
    "двенадцатый\n",
    "двенадцать\n",
    "дверь\n",
    "двух\n",
    "девятнадцатый\n",
    "девятнадцать\n",
    "девятый\n",
    "девять\n",
    "действительно\n",
    "дел\n",
    "делал\n",
    "делать\n",
    "делаю\n",
    "дело\n",
    "день\n",
    "деньги\n",
    "десятый\n",
    "десять\n",
    "для\n",
    "до\n",
    "довольно\n",
    "долго\n",
    "должен\n",
    "должно\n",
    "должный\n",
    "дом\n",
    "дорога\n",
    "друг\n",
    "другая\n",
    "другие\n",
    "других\n",
    "друго\n",
    "другое\n",
    "другой\n",
    "думать\n",
    "душа\n",
    "е\n",
    "его\n",
    "ее\n",
    "ей\n",
    "ему\n",
    "если\n",
    "есть\n",
    "еще\n",
    "ещё\n",
    "ею\n",
    "её\n",
    "ж\n",
    "ждать\n",
    "же\n",
    "жена\n",
    "женщина\n",
    "жизнь\n",
    "жить\n",
    "за\n",
    "занят\n",
    "занята\n",
    "занято\n",
    "заняты\n",
    "затем\n",
    "зато\n",
    "зачем\n",
    "здесь\n",
    "земля\n",
    "знать\n",
    "значит\n",
    "значить\n",
    "и\n",
    "иди\n",
    "идти\n",
    "из\n",
    "или\n",
    "им\n",
    "имеет\n",
    "имел\n",
    "именно\n",
    "иметь\n",
    "ими\n",
    "имя\n",
    "иногда\n",
    "их\n",
    "к\n",
    "каждая\n",
    "каждое\n",
    "каждые\n",
    "каждый\n",
    "кажется\n",
    "казаться\n",
    "как\n",
    "какая\n",
    "какой\n",
    "кем\n",
    "книга\n",
    "когда\n",
    "кого\n",
    "ком\n",
    "комната\n",
    "кому\n",
    "конец\n",
    "конечно\n",
    "которая\n",
    "которого\n",
    "которой\n",
    "которые\n",
    "который\n",
    "которых\n",
    "кроме\n",
    "кругом\n",
    "кто\n",
    "куда\n",
    "лежать\n",
    "лет\n",
    "ли\n",
    "лицо\n",
    "лишь\n",
    "лучше\n",
    "любить\n",
    "люди\n",
    "м\n",
    "маленький\n",
    "мало\n",
    "мать\n",
    "машина\n",
    "между\n",
    "меля\n",
    "менее\n",
    "меньше\n",
    "меня\n",
    "место\n",
    "миллионов\n",
    "мимо\n",
    "минута\n",
    "мир\n",
    "мира\n",
    "мне\n",
    "много\n",
    "многочисленная\n",
    "многочисленное\n",
    "многочисленные\n",
    "многочисленный\n",
    "мной\n",
    "мною\n",
    "мог\n",
    "могу\n",
    "могут\n",
    "мож\n",
    "может\n",
    "может быть\n",
    "можно\n",
    "можхо\n",
    "мои\n",
    "мой\n",
    "мор\n",
    "москва\n",
    "мочь\n",
    "моя\n",
    "моё\n",
    "мы\n",
    "на\n",
    "наверху\n",
    "над\n",
    "надо\n",
    "назад\n",
    "наиболее\n",
    "найти\n",
    "наконец\n",
    "нам\n",
    "нами\n",
    "народ\n",
    "нас\n",
    "начала\n",
    "начать\n",
    "наш\n",
    "наша\n",
    "наше\n",
    "наши\n",
    "не\n",
    "него\n",
    "недавно\n",
    "недалеко\n",
    "нее\n",
    "ней\n",
    "некоторый\n",
    "нельзя\n",
    "нем\n",
    "немного\n",
    "нему\n",
    "непрерывно\n",
    "нередко\n",
    "несколько\n",
    "нет\n",
    "нею\n",
    "неё\n",
    "ни\n",
    "нибудь\n",
    "ниже\n",
    "низко\n",
    "никакой\n",
    "никогда\n",
    "никто\n",
    "никуда\n",
    "ним\n",
    "ними\n",
    "них\n",
    "ничего\n",
    "ничто\n",
    "но\n",
    "новый\n",
    "нога\n",
    "ночь\n",
    "ну\n",
    "нужно\n",
    "нужный\n",
    "нх\n",
    "о\n",
    "об\n",
    "оба\n",
    "обычно\n",
    "один\n",
    "одиннадцатый\n",
    "одиннадцать\n",
    "однажды\n",
    "однако\n",
    "одного\n",
    "одной\n",
    "оказаться\n",
    "окно\n",
    "около\n",
    "он\n",
    "она\n",
    "они\n",
    "оно\n",
    "опять\n",
    "особенно\n",
    "остаться\n",
    "от\n",
    "ответить\n",
    "отец\n",
    "откуда\n",
    "отовсюду\n",
    "отсюда\n",
    "очень\n",
    "первый\n",
    "перед\n",
    "писать\n",
    "плечо\n",
    "по\n",
    "под\n",
    "подойди\n",
    "подумать\n",
    "пожалуйста\n",
    "позже\n",
    "пойти\n",
    "пока\n",
    "пол\n",
    "получить\n",
    "помнить\n",
    "понимать\n",
    "понять\n",
    "пор\n",
    "пора\n",
    "после\n",
    "последний\n",
    "посмотреть\n",
    "посреди\n",
    "потом\n",
    "потому\n",
    "почему\n",
    "почти\n",
    "правда\n",
    "прекрасно\n",
    "при\n",
    "про\n",
    "просто\n",
    "против\n",
    "процентов\n",
    "путь\n",
    "пятнадцатый\n",
    "пятнадцать\n",
    "пятый\n",
    "пять\n",
    "работа\n",
    "работать\n",
    "раз\n",
    "разве\n",
    "рано\n",
    "раньше\n",
    "ребенок\n",
    "решить\n",
    "россия\n",
    "рука\n",
    "русский\n",
    "ряд\n",
    "рядом\n",
    "с\n",
    "с кем\n",
    "сам\n",
    "сама\n",
    "сами\n",
    "самим\n",
    "самими\n",
    "самих\n",
    "само\n",
    "самого\n",
    "самой\n",
    "самом\n",
    "самому\n",
    "саму\n",
    "самый\n",
    "свет\n",
    "свое\n",
    "своего\n",
    "своей\n",
    "свои\n",
    "своих\n",
    "свой\n",
    "свою\n",
    "сделать\n",
    "сеаой\n",
    "себе\n",
    "себя\n",
    "сегодня\n",
    "седьмой\n",
    "сейчас\n",
    "семнадцатый\n",
    "семнадцать\n",
    "семь\n",
    "сидеть\n",
    "сила\n",
    "сих\n",
    "сказал\n",
    "сказала\n",
    "сказать\n",
    "сколько\n",
    "слишком\n",
    "слово\n",
    "случай\n",
    "смотреть\n",
    "сначала\n",
    "снова\n",
    "со\n",
    "собой\n",
    "собою\n",
    "советский\n",
    "совсем\n",
    "спасибо\n",
    "спросить\n",
    "сразу\n",
    "стал\n",
    "старый\n",
    "стать\n",
    "стол\n",
    "сторона\n",
    "стоять\n",
    "страна\n",
    "суть\n",
    "считать\n",
    "т\n",
    "та\n",
    "так\n",
    "такая\n",
    "также\n",
    "таки\n",
    "такие\n",
    "такое\n",
    "такой\n",
    "там\n",
    "твои\n",
    "твой\n",
    "твоя\n",
    "твоё\n",
    "те\n",
    "тебе\n",
    "тебя\n",
    "тем\n",
    "теми\n",
    "теперь\n",
    "тех\n",
    "то\n",
    "тобой\n",
    "тобою\n",
    "товарищ\n",
    "тогда\n",
    "того\n",
    "тоже\n",
    "только\n",
    "том\n",
    "тому\n",
    "тот\n",
    "тою\n",
    "третий\n",
    "три\n",
    "тринадцатый\n",
    "тринадцать\n",
    "ту\n",
    "туда\n",
    "тут\n",
    "ты\n",
    "тысяч\n",
    "у\n",
    "увидеть\n",
    "уж\n",
    "уже\n",
    "улица\n",
    "уметь\n",
    "утро\n",
    "хороший\n",
    "хорошо\n",
    "хотел бы\n",
    "хотеть\n",
    "хоть\n",
    "хотя\n",
    "хочешь\n",
    "час\n",
    "часто\n",
    "часть\n",
    "чаще\n",
    "чего\n",
    "человек\n",
    "чем\n",
    "чему\n",
    "через\n",
    "четвертый\n",
    "четыре\n",
    "четырнадцатый\n",
    "четырнадцать\n",
    "что\n",
    "чтоб\n",
    "чтобы\n",
    "чуть\n",
    "шестнадцатый\n",
    "шестнадцать\n",
    "шестой\n",
    "шесть\n",
    "эта\n",
    "эти\n",
    "этим\n",
    "этими\n",
    "этих\n",
    "это\n",
    "этого\n",
    "этой\n",
    "этом\n",
    "этому\n",
    "этот\n",
    "эту\n",
    "я\n",
    "являюсь'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейского',\n",
       " 'армии',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'боснии',\n",
       " 'бугойно',\n",
       " 'вермахта',\n",
       " 'верховного',\n",
       " 'во',\n",
       " 'военных',\n",
       " 'воздушно',\n",
       " 'войны',\n",
       " 'войск',\n",
       " 'вражеское',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'го',\n",
       " 'года',\n",
       " 'горнопехотного',\n",
       " 'городе',\n",
       " 'движения',\n",
       " 'десант',\n",
       " 'десантная',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западной',\n",
       " 'известна',\n",
       " 'или',\n",
       " 'историографии',\n",
       " 'июня',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинированная',\n",
       " 'корпуса',\n",
       " 'лука',\n",
       " 'мая',\n",
       " 'мировой',\n",
       " 'миссий',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательная',\n",
       " 'наступление',\n",
       " 'находившихся',\n",
       " 'ноаю',\n",
       " 'нём',\n",
       " 'операции',\n",
       " 'операция',\n",
       " 'освободительного',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'проводилась',\n",
       " 'районе',\n",
       " 'седьмое',\n",
       " 'сербохорв',\n",
       " 'союзных',\n",
       " 'сс',\n",
       " 'сухопутная',\n",
       " 'также',\n",
       " 'танковой',\n",
       " 'уничтожения',\n",
       " 'участвовали',\n",
       " 'учреждений',\n",
       " 'целью',\n",
       " 'части',\n",
       " 'штаба',\n",
       " 'югославии',\n",
       " 'югославской',\n",
       " 'яйце']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([text])\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = cv.transform([stop_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейского',\n",
       " 'армии',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'боснии',\n",
       " 'бугойно',\n",
       " 'вермахта',\n",
       " 'верховного',\n",
       " 'во',\n",
       " 'военных',\n",
       " 'воздушно',\n",
       " 'войны',\n",
       " 'войск',\n",
       " 'вражеское',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'го',\n",
       " 'года',\n",
       " 'горнопехотного',\n",
       " 'городе',\n",
       " 'движения',\n",
       " 'десант',\n",
       " 'десантная',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западной',\n",
       " 'известна',\n",
       " 'или',\n",
       " 'историографии',\n",
       " 'июня',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинированная',\n",
       " 'корпуса',\n",
       " 'лука',\n",
       " 'мая',\n",
       " 'мировой',\n",
       " 'миссий',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательная',\n",
       " 'наступление',\n",
       " 'находившихся',\n",
       " 'ноаю',\n",
       " 'нём',\n",
       " 'операции',\n",
       " 'операция',\n",
       " 'освободительного',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'проводилась',\n",
       " 'районе',\n",
       " 'седьмое',\n",
       " 'сербохорв',\n",
       " 'союзных',\n",
       " 'сс',\n",
       " 'сухопутная',\n",
       " 'также',\n",
       " 'танковой',\n",
       " 'уничтожения',\n",
       " 'участвовали',\n",
       " 'учреждений',\n",
       " 'целью',\n",
       " 'части',\n",
       " 'штаба',\n",
       " 'югославии',\n",
       " 'югославской',\n",
       " 'яйце']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + lemmatization\\stemming + TfidfVectorizer + передавайте в векторайзер свой токенизатор (например из razdel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = simple_word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_text)):\n",
    "    new_text[i] = pymorph.parse(new_text[i])[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['югославской',\n",
       " 'историографии',\n",
       " 'также',\n",
       " 'известна',\n",
       " 'как',\n",
       " '«',\n",
       " 'седьмое',\n",
       " 'вражеское',\n",
       " 'наступление',\n",
       " '»',\n",
       " 'или',\n",
       " 'десант',\n",
       " 'на',\n",
       " 'дрвар',\n",
       " '(',\n",
       " 'сербохорв',\n",
       " '.',\n",
       " 'десант',\n",
       " 'на',\n",
       " 'дрвар',\n",
       " '/',\n",
       " 'desant',\n",
       " 'na',\n",
       " 'drvar',\n",
       " ')',\n",
       " '—',\n",
       " 'комбинированная',\n",
       " 'воздушно-десантная',\n",
       " 'и',\n",
       " 'сухопутная',\n",
       " 'наступательная',\n",
       " 'операция',\n",
       " 'войск',\n",
       " '2-й',\n",
       " 'танковой',\n",
       " 'армии',\n",
       " 'вермахта',\n",
       " 'во',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'мировой',\n",
       " 'войны',\n",
       " '.',\n",
       " 'проводилась',\n",
       " 'в',\n",
       " 'западной',\n",
       " 'боснии',\n",
       " 'в',\n",
       " 'районе',\n",
       " 'бугойно',\n",
       " '—',\n",
       " 'яйце',\n",
       " '—',\n",
       " 'баня-лука',\n",
       " '—',\n",
       " 'приедор',\n",
       " '—',\n",
       " 'бихач',\n",
       " '—',\n",
       " 'книн',\n",
       " 'в',\n",
       " 'период',\n",
       " 'с',\n",
       " '25',\n",
       " 'мая',\n",
       " 'по',\n",
       " '6',\n",
       " 'июня',\n",
       " '1944',\n",
       " 'года',\n",
       " 'с',\n",
       " 'целью',\n",
       " 'уничтожения',\n",
       " 'верховного',\n",
       " 'штаба',\n",
       " 'ноаю',\n",
       " 'в',\n",
       " 'городе',\n",
       " 'дрвар',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'находившихся',\n",
       " 'при',\n",
       " 'нём',\n",
       " 'учреждений',\n",
       " 'народно-освободительного',\n",
       " 'движения',\n",
       " 'югославии',\n",
       " 'и',\n",
       " 'союзных',\n",
       " 'военных',\n",
       " 'миссий',\n",
       " '.',\n",
       " 'в',\n",
       " 'операции',\n",
       " 'участвовали',\n",
       " '500-й',\n",
       " 'парашютно-десантный',\n",
       " 'батальон',\n",
       " 'сс',\n",
       " ',',\n",
       " 'а',\n",
       " 'также',\n",
       " 'части',\n",
       " '15-го',\n",
       " 'горнопехотного',\n",
       " 'армейского',\n",
       " 'корпуса',\n",
       " 'и',\n",
       " '5-го',\n",
       " 'горнопехотного',\n",
       " 'корпуса',\n",
       " 'сс',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text1 = tokenize_with_razdel(text.lower())\n",
    "new_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(new_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '1944',\n",
       " '25',\n",
       " '500',\n",
       " 'desant',\n",
       " 'drvar',\n",
       " 'na',\n",
       " 'армейского',\n",
       " 'армии',\n",
       " 'баня',\n",
       " 'батальон',\n",
       " 'бихач',\n",
       " 'боснии',\n",
       " 'бугойно',\n",
       " 'вермахта',\n",
       " 'верховного',\n",
       " 'во',\n",
       " 'военных',\n",
       " 'воздушно',\n",
       " 'войны',\n",
       " 'войск',\n",
       " 'вражеское',\n",
       " 'время',\n",
       " 'второй',\n",
       " 'го',\n",
       " 'года',\n",
       " 'горнопехотного',\n",
       " 'городе',\n",
       " 'движения',\n",
       " 'десант',\n",
       " 'десантная',\n",
       " 'десантный',\n",
       " 'дрвар',\n",
       " 'западной',\n",
       " 'известна',\n",
       " 'или',\n",
       " 'историографии',\n",
       " 'июня',\n",
       " 'как',\n",
       " 'книн',\n",
       " 'комбинированная',\n",
       " 'корпуса',\n",
       " 'лука',\n",
       " 'мая',\n",
       " 'мировой',\n",
       " 'миссий',\n",
       " 'на',\n",
       " 'народно',\n",
       " 'наступательная',\n",
       " 'наступление',\n",
       " 'находившихся',\n",
       " 'ноаю',\n",
       " 'нём',\n",
       " 'операции',\n",
       " 'операция',\n",
       " 'освободительного',\n",
       " 'парашютно',\n",
       " 'период',\n",
       " 'по',\n",
       " 'при',\n",
       " 'приедор',\n",
       " 'проводилась',\n",
       " 'районе',\n",
       " 'седьмое',\n",
       " 'сербохорв',\n",
       " 'союзных',\n",
       " 'сс',\n",
       " 'сухопутная',\n",
       " 'также',\n",
       " 'танковой',\n",
       " 'уничтожения',\n",
       " 'участвовали',\n",
       " 'учреждений',\n",
       " 'целью',\n",
       " 'части',\n",
       " 'штаба',\n",
       " 'югославии',\n",
       " 'югославской',\n",
       " 'яйце']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower + lemmatization\\stemming + TfidfVectorizer (используйте ngrams(2, 2)) + передавайте в векторайзер свой токенизатор (например из razdel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'югославской историографии также известна как «седьмое вражеское наступление» или десант на дрвар (сербохорв. десант на дрвар / desant na drvar) — комбинированная воздушно-десантная и сухопутная наступательная операция войск 2-й танковой армии вермахта во время второй мировой войны. проводилась в западной боснии в районе бугойно — яйце — баня-лука — приедор — бихач — книн в период с 25 мая по 6 июня 1944 года с целью уничтожения верховного штаба ноаю в городе дрвар, а также находившихся при нём учреждений народно-освободительного движения югославии и союзных военных миссий. в операции участвовали 500-й парашютно-десантный батальон сс, а также части 15-го горнопехотного армейского корпуса и 5-го горнопехотного корпуса сс.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = tokenize_with_razdel(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15 го',\n",
       " 'баня лука',\n",
       " 'воздушно десантная',\n",
       " 'народно освободительного',\n",
       " 'парашютно десантный']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
